# Forward-backward argorithm

In this assignment, you will implement the [forward-backward algorithm](https://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm) from scratch.
This does not require any novel knowledge of programming on top of what you have seen in the previous assignments.
The [core code](hiddenMarkov.py) provided in this case is very sparse and meant only to serve as a guideline for program structure.

## The algorithm

Forward-backward algorithm is very similar to the Viterbi algorithm and is discussed in the lecture notes.
The difference is, when provided an observed sequence, forward-backward yields **posterior marginal probabilities** of all hidden states for each position, while Viterbi only yields the **most likely hidden state sequence**.

When you complete this assignment, you should realize these are not necessarily the same for a given observation.

Note that the [Wikipedia description](https://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm) of the forward-backward algorithm is vectorized and not as clear as the pseudocode for Viterbi.
In this case you are better off making use of the lecture notes.

## The input

Unlike the Viterbi assignment, you will need to parse your parameters from a file for this assignment.
The file will be formatted as follows :

  * 2 integers n and m signifying number of states and alphabet size
  * n lines of initial probabilities
  * n x n lines of transition probabilities
  * n x m lines of emission probabilities

An example [input file](sample_parameters.dat), representing the fair/biased coin example from the viterbi assignment is provided.
You will implement a parser for this format, which will take the parameter filename and return initial, transition and emission probabilities.
Your code should check for sanity of parameters and should refuse to run for broken parameters.
Your code should take the parameter file as the -p parameter and should not run without it.

## The program

Implement the viterbi and forward-backward algorithms as **separate functions**.
Comment your code very very well.
There will be no partial credits in this assignment.
It will be impossible for me to help you unless your code has **excellent** comments.
Make sure you refer to the mathematical relations you are making use of in your comments.

## The output

Your program should output two consecutive hidden state sequences.

  * Maximum likelihood hidden state sequence as generated by Viterbi,
  * String of maximum marginal posterior hidden states for each position, as generated by forward-backward.

Sample output :

```
python2 hiddenMArkov.py -p sample_parameters.dat -o HTHTHTHHHTHT
FFFFFFFFFFFF
FFFBBBFFFFFF
```

If the optional parameter **-v** is provided, your program should follow its regular output with the full posterior marginal probability distribution.

Sample output :

```
python2 hiddenMarkov.py -p sample_parameters.dat -o HTHTHTHHHTHT -v
FFFFFFFFFFFF
FFFBBBFFFFFF
[[ 0.48601609  0.51398391]
 [ 0.34585445  0.65414555]
 [ 0.40758347  0.59241653]
 [ 0.32021569  0.67978431]
 [ 0.42103828  0.57896172]
 [ 0.37525642  0.62474358]
 [ 0.54707643  0.45292357]
 [ 0.59563906  0.40436094]
 [ 0.54554938  0.45445062]
 [ 0.37142862  0.62857138]
 [ 0.41392149  0.58607851]
 [ 0.30800078  0.69199922]]
```

## Tips and tricks

  * You can assume each hidden state and emission symbol will be represented by a single character for simplicity.
  * Make no further assumptions about the parameters.
  * If your code does not run for arbitrary n and m, it is broken and you get no points.
  * If your code takes un-sane parameters and generates bogus output, it is broken and you get no points.
